{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reads through the numerous JSON files and extracts only the relevant tweets based on string matching.\n",
    "\n",
    "The substrings searched for are actually hashtags, and by nature of which, will be found as exact matches within the tweet text body.\n",
    "\n",
    "These hashtags would also exist in the _entities_ json element in an array, which will be used later for exploration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put these at the top of every notebook, to get automatic reloading and inline plotting\n",
    "from IPython.core.display import display, HTML\n",
    "import pandas as pd\n",
    "%reload_ext autoreload\n",
    "%autoreload 1\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('max_colwidth',100)    \n",
    "\n",
    "display(HTML(\"<style>.container { width:95% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:95% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import json\n",
    "from itertools import combinations, takewhile\n",
    "import collections\n",
    "\n",
    "from simhash import Simhash, SimhashIndex\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.feature import OneHotEncoder, StringIndexer, VectorAssembler\n",
    "# from pyspark.ml.feature import OneHotEncoderEstimator\n",
    "# OneHotEncoderEstimator is available starting from Spark 2.3\n",
    "from pyspark.ml.classification import LogisticRegression, LogisticRegressionModel\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -ls -h '/user/ivy2/Tweets/' > '/home/sriharis/git_projects/BigDataEngg/final_project/file_list.txt'\n",
    "tweets_path = '/user/ivy2/Tweets/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json_file = \"hdfs:///user/ivy2/Tweets/tweets*.json\"\n",
    "json_file = \"hdfs:///user/ivy2/Tweets/tweets2017*.json\"\n",
    "df=spark.read.json(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+--------------------+-------------------------+-----------------------+--------------------+-----------+---------+--------------------+--------------------+-------------------+------------------+-----------+--------------+-----------------+---------+-------------+------------------+----------+----------+-------------+---------+----------------------------+--------------------------+\n",
      "|            id_str|                text|in_reply_to_status_id_str|in_reply_to_user_id_str|          created_at|user_id_str|user_name|user_followers_count|user_favorites_count|user_statuses_count|user_friends_count|coordinates|favorite_count|entities_hashtags|favorited|place_country|place_country_code|place_name|place_type|retweet_count|retweeted|retweeted_status_user_id_str|retweeted_status_user_name|\n",
      "+------------------+--------------------+-------------------------+-----------------------+--------------------+-----------+---------+--------------------+--------------------+-------------------+------------------+-----------+--------------+-----------------+---------+-------------+------------------+----------+----------+-------------+---------+----------------------------+--------------------------+\n",
      "|878028835710619648|RT @millselle: my...|                     null|                   null|Thu Jun 22 23:16:...| 2222587376|GOAT.ðŸ‡³ðŸ‡¬|                 495|               34038|              23409|               341|       null|             0|               []|    false|         null|              null|      null|      null|            0|    false|                   624398529|                Elle Mills|\n",
      "|878028835832209410|You clean up nice...|                     null|                   null|Thu Jun 22 23:16:...|  588687170|   Gordon|                 146|                 512|               1748|               509|       null|             0|               []|    false|         null|              null|      null|      null|            0|    false|                        null|                      null|\n",
      "+------------------+--------------------+-------------------------+-----------------------+--------------------+-----------+---------+--------------------+--------------------+-------------------+------------------+-----------+--------------+-----------------+---------+-------------+------------------+----------+----------+-------------+---------+----------------------------+--------------------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fields_to_keep = [\"id_str\", \n",
    "                  \"text\",\n",
    "                  \"in_reply_to_status_id_str\",\n",
    "                  \"in_reply_to_user_id_str\", \n",
    "                  \"created_at\",\n",
    "                  # User columns\n",
    "                  \"user.id_str\",\n",
    "                  \"user.name\",\n",
    "                  \"user.followers_count\",\n",
    "                  \"user.favourites_count\",\n",
    "                  \"user.statuses_count\",\n",
    "                  \"user.friends_count\",\n",
    "                  # Other attributes\n",
    "                  \"coordinates\",\n",
    "                  \"favorite_count\",\n",
    "                  \"entities.hashtags\",\n",
    "                  \"favorited\", \n",
    "                  \"place.country\",\n",
    "                  \"place.country_code\",\n",
    "                  \"place.name\",\n",
    "                  \"place.place_type\",\n",
    "                  # Retweet columns\n",
    "                  \"retweet_count\", \n",
    "                  \"retweeted\",\n",
    "                  \"retweeted_status.user.id_str\",\n",
    "                  \"retweeted_status.user.name\"\n",
    "                 ]\n",
    "\n",
    "df = df.selectExpr(\"id_str\", \n",
    "              \"text\",\n",
    "              \"in_reply_to_status_id_str\",\n",
    "              \"in_reply_to_user_id_str\", \n",
    "              \"created_at\",\n",
    "              \"user.id_str as user_id_str\",\n",
    "              \"user.name as user_name\",\n",
    "              \"user.followers_count as user_followers_count\",\n",
    "              \"user.favourites_count as user_favorites_count\",\n",
    "              \"user.statuses_count as user_statuses_count\",\n",
    "              \"user.friends_count as user_friends_count\",\n",
    "              \"coordinates\",\n",
    "              \"favorite_count\",\n",
    "              \"entities.hashtags as entities_hashtags\",\n",
    "              \"favorited\", \n",
    "              \"place.country as place_country\",\n",
    "              \"place.country_code as place_country_code\",\n",
    "              \"place.name as place_name\",\n",
    "              \"place.place_type as place_type\",\n",
    "              \"retweet_count\", \n",
    "              \"retweeted\",\n",
    "              \"retweeted_status.user.id_str as retweeted_status_user_id_str\",\n",
    "              \"retweeted_status.user.name as retweeted_status_user_name\")\n",
    "df.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1489935"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31831"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# uc_favored_tags = [\"uchicago\", \"uchearing\", \"universityofchicago\", \"pritzkerschoolofmedicine\",\n",
    "#                    \"uofc\", \"maroonmade\", \"chicagobooth\"]\n",
    "# nw_favored_tags = [\"northwestern\"]\n",
    "# upenn_favored_tags = [\"upenn\", \"penn\", \"uofpenn\", \"universityofpennsylvania\", \"pennlaw\", \"upennhearing\"]\n",
    "# uic_favored_tags = [\"UIC\", \"UICProud\"]\n",
    "# mit_favored_tags = [\"MIT\"]\n",
    "# stanford_favored_tags = [\"stanford\"]\n",
    "\n",
    "df_university  = df.where('lower(text) like \"%uchicago%\"\\\n",
    "                            or lower(text) like \"%uchearing%\"\\\n",
    "                            or lower(text) like \"%universityofchicago%\"\\\n",
    "                            or lower(text) like \"%pritzkerschoolofmedicine%\"\\\n",
    "                            or lower(text) like \"%uofc%\"\\\n",
    "                            or lower(text) like \"%chicagobooth%\"\\\n",
    "                            or lower(text) like \"%maroonmade%\"\\\n",
    "                            or lower(text) like \"%northwestern%\"\\\n",
    "                            or lower(text) like \"%upenn%\"\\\n",
    "                            or lower(text) like \"%upennhearing%\"\\\n",
    "                            or lower(text) like \"%penn%\"\\\n",
    "                            or lower(text) like \"%uofpenn%\"\\\n",
    "                            or lower(text) like \"%universityofpennsylvania%\"\\\n",
    "                            or lower(text) like \"%pennlaw%\"\\\n",
    "                            or lower(text) like \"%uicproud%\"\\\n",
    "                            or lower(text) like \"%uic %\"\\\n",
    "                            or lower(text) like \"%stanford%\"'\n",
    "                         )#or lower(text) like \"%mit %\"\\\n",
    "df_university.cache()\n",
    "df_university.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   entities_hashtags|\n",
      "+--------------------+\n",
      "|[[[7, 19], abeced...|\n",
      "|                  []|\n",
      "|[[[36, 44], Argon...|\n",
      "|  [[[112, 115], Wx]]|\n",
      "|[[[67, 76], Break...|\n",
      "|[[[108, 114], dad...|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|   [[[91, 95], CBC]]|\n",
      "|[[[43, 57], Yuvas...|\n",
      "|                  []|\n",
      "|                  []|\n",
      "|[[[103, 111], B1G...|\n",
      "|[[[91, 99], CBCNe...|\n",
      "|                  []|\n",
      "|                  []|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_university.select(\"entities_hashtags\").limit(50).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n",
      "2019-03-22 02:10:21,528 INFO  [main] fs.TrashPolicyDefault (TrashPolicyDefault.java:moveToTrash(182)) - Moved: 'hdfs://nameservice1/user/sriharis/project' to trash at: hdfs://nameservice1/user/sriharis/.Trash/Current/user/sriharis/project1553238621501\n"
     ]
    }
   ],
   "source": [
    "!hdfs dfs -rm -r \"hdfs:///user/sriharis/project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "hdfsdir = \"hdfs:///user/sriharis/project\"\n",
    "df_university.coalesce(1).write.format(\"json\").save(hdfsdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: log4j.properties is not found. HADOOP_CONF_DIR may be incomplete.\n",
      "Java HotSpot(TM) 64-Bit Server VM warning: ignoring option MaxPermSize=512M; support was removed in 8.0\n",
      "Found 2 items\n",
      "-rw-r--r--   3 sriharis sriharis          0 2019-03-22 02:10 /user/sriharis/project/_SUCCESS\n",
      "-rw-r--r--   3 sriharis sriharis     16.8 M 2019-03-22 02:10 /user/sriharis/project/part-00000-ad6a81ae-9524-4fa5-97e1-9babda4718a3-c000.json\n"
     ]
    }
   ],
   "source": [
    "!hadoop fs -ls -h /user/sriharis/project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
